{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.contrib import text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greg Bruss\n",
    "## KEN2570 - Spring 2019 Project\n",
    "\n",
    "In our Natural Language Processing class, we saw how we can train a word2vec word embedding model on a large scale corpus. These \"pre-trained\" word vectors can be applied in a variety of tasks. The task I will be looking at in this notebook is the task of finding analogies.\n",
    "\n",
    "An analogy is defined as a comparison between one thing and another, and represents a form of correspondence or similarity. Although the two terms compared are different, they share fundamental similarities that allows a relationship to be inferred. An example would be \"Man is to woman, as son is to daughter\". \n",
    "\n",
    "#### Why analogy finding is useful\n",
    "\"Analogical reasoning\" is an important skill that anyone who truly understands language should know. An \"analogical argument\" is an explicit representation of a form of analogical reasoning that cites accepted similarities between two systems to support the conclusion that some further similarity exists [1]. It is clear that any AI system would need to have a grasp of these similarities, particularly because much of human speech uses analogy as a valid form of expression.\n",
    "\n",
    "### Getting Pretrained Word Vectors\n",
    "\n",
    "We need a way to get the pretrained word vectors. We can make use of the GluonNLP package (https://gluon-nlp.mxnet.io/), which makes it easy to evaluate and train word embeddings, using any choice of word2vec, fastText, or GloVe models. Word2Vec Models were introduced by Mikolov et. al [3], and FastText models by Bojanowski et. al [4]. GloVe models were introduced by Pennington et al [5].\n",
    "\n",
    "We can make use of the mxnet.contrib.text API, which allows loading of pre-trained embedding vectors for text tokens and storing them in the mxnet.ndarray.NDArray format (MXNet documentation - https://mxnet.incubator.apache.org/api/python/contrib/text.html)\n",
    "\n",
    "The keys of the pretrained files will be either glove or fasttext, as these are the ones supported in the MXNet model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['glove', 'fasttext'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.embedding.get_pretrained_file_names().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Text\n",
    "\n",
    "I will use the GloVe word embedding. It is trained on the \"Wikipedia 2014 + Gigaword 5\" dataset. A quick summary of this dataset is the following:  \n",
    "    \n",
    "    6 Billion tokens  \n",
    "    400K vocab (uncased)  \n",
    "    50, 100, 200, and 300-Dimensional vectors available  \n",
    "    822 mb download  \n",
    "    \n",
    "    \n",
    "    100d, 200d, & 300d vectors are available, downloads as glove.6B.zip  \n",
    "    \n",
    "    (See https://nlp.stanford.edu/projects/glove/ for further details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glove.42B.300d.txt', 'glove.6B.50d.txt', 'glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt', 'glove.840B.300d.txt', 'glove.twitter.27B.25d.txt', 'glove.twitter.27B.50d.txt', 'glove.twitter.27B.100d.txt', 'glove.twitter.27B.200d.txt']\n"
     ]
    }
   ],
   "source": [
    "print(text.embedding.get_pretrained_file_names('glove'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can instantiate a pre-trained embedding using MXNet's text.embedding.create API. In this case I will use a 300-Dimensional word embedding,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6b50d = text.embedding.create(\n",
    "    'glove', pretrained_file_name='glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words in this pre-trained vector's dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary size of the 50d glove model is: 400001\n"
     ]
    }
   ],
   "source": [
    "print(\"The dictionary size of the 50d glove model is:\", len(glove_6b50d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel for this dictionary, lets look at some of the words using MXNet's index-to-token function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the word 'knowledge' is: 2490\n",
      "Index of the word 'data' is: 934\n",
      "Index of the word 'robot' is: 9248\n",
      "Index of the word 'human' is: 474\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of the word 'knowledge' is:\", glove_6b50d.token_to_idx['knowledge'])\n",
    "print(\"Index of the word 'data' is:\", glove_6b50d.token_to_idx['data'])\n",
    "print(\"Index of the word 'robot' is:\", glove_6b50d.token_to_idx['robot'])\n",
    "print(\"Index of the word 'human' is:\", glove_6b50d.token_to_idx['human'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making use of the GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, we can use the word embedding for the analogy task by searching for words that appear closer in the Vector Space, or that can be reached using a \"relationship vector\" which takes as input the analogical relationship \n",
    "\n",
    "####  \"A --> B:  C --> D\". Given A,B, relationship(A,B), and C, find D\n",
    "\n",
    "We can use something like K-Nearest Neighbours [6] for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # The added 1e-9 is for numerical stability\n",
    "    cos = nd.dot(W, x.reshape((-1,))) / (\n",
    "        (nd.sum(W * W, axis=1) + 1e-9).sqrt() * nd.sum(x * x).sqrt())\n",
    "    topk = nd.topk(cos, k=k, ret_typ='indices').asnumpy().astype('int32')\n",
    "    return topk, [cos[i].asscalar() for i in topk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the analogy problem, we need to find the word vector that is most similar to the result vector of  vec(ùëê)+vec(ùëè)‚àívec(ùëé) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = embed.get_vecs_by_tokens([token_a, token_b, token_c])\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
    "    return embed.idx_to_token[topk[0]]  # Remove unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Analogies: Will use 3 categories of analogy with 15 test cases each\n",
    "\n",
    "The different types of analogy are:\n",
    "\n",
    "#### capital: country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adjective: superlative: adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biggest'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### present-tense verb: past tense verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achieved'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('accept', 'accepted', 'achieve', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['accept', 'accepted', 'achieve', 'achieved'], ['add', 'added', 'agree', 'agreed'], ['allow', 'allowed', 'announce', 'announced'], ['appear', 'appeared', 'apply', 'applied'], ['ask', 'asked', 'attend', 'attended'], ['become', 'became', 'believe', 'believed'], ['consider', 'considered', 'continue', 'continued'], ['create', 'created', 'decide', 'decided'], ['describe', 'described', 'develop', 'developed'], ['discover', 'discovered', 'enjoy', 'enjoyed'], ['ensure', 'ensured', 'establish', 'established'], ['expect', 'expected', 'follow', 'followed'], ['hear', 'heard', 'identify', 'identified'], ['improve', 'improved', 'include', 'included'], ['introduce', 'introduced', 'involve', 'involved'], ['locate', 'located', 'lose', 'lost'], ['manage', 'managed', 'marry', 'married'], ['perform', 'performed', 'provide', 'provided'], ['publish', 'published', 'receive', 'received'], ['reduce', 'reduced', 'refer', 'referred'], ['relate', 'related', 'remain', 'remained'], ['replace', 'replaced', 'require', 'required'], ['seem', 'seemed', 'send', 'sent'], ['spend', 'spent', 'tell', 'told'], ['understand', 'understood', 'unite', 'united']]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"present-past.txt\", \"r\")\n",
    "analogies = f.readlines()\n",
    "for i in range(len(analogies)):\n",
    "    analogies[i] = analogies[i].lower()\n",
    "    analogies[i]=analogies[i].split()\n",
    "\n",
    "print(analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_answer = []\n",
    "for i in range(len(analogies)):\n",
    "    real_answer.append(analogies[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer=[get_analogy(analogy[0], analogy[1], analogy[2], glove_6b50d) for analogy in analogies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['achieved', 'insisted', 'announce', 'apply', 'attend', 'thought', 'become', 'decided', 'development', 'except', 'ensured', 'on', 'identify', 'included', 'involving', 'located', 'marry', 'provided', 'received', 'referred', 'remain', 'required', 'send', 'knew', 'unite']\n",
      "['achieved', 'agreed', 'announced', 'applied', 'attended', 'believed', 'continued', 'decided', 'developed', 'enjoyed', 'established', 'followed', 'identified', 'included', 'involved', 'lost', 'married', 'provided', 'received', 'referred', 'remained', 'required', 'sent', 'told', 'united']\n"
     ]
    }
   ],
   "source": [
    "print(predicted_answer)\n",
    "print(real_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(predicted_answer)\n",
    "correct = 0\n",
    "for i in range(len(predicted_answer)):\n",
    "    if predicted_answer[i] == real_answer[i]:\n",
    "                correct +=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct:  7\n",
      "Total asked:  25\n",
      "The accuracy on the  present-past.txt dataset is:  28.000000000000004\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/total * 100\n",
    "print(\"Total correct: \", correct)\n",
    "print(\"Total asked: \", total)\n",
    "print(\"The accuracy on the \", f.name,\"dataset is: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "[1] Bartha, Paul, \"Analogy and Analogical Reasoning\", The Stanford Encyclopedia of Philosophy (Spring 2019 Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/spr2019/entries/reasoning-analogy/>.\n",
    "\n",
    "[2] Zhang, A, \"Dive into Deep Learning\" (2019), Z. Lipton, M. Li, A. Smola URL = https://d2l.ai/\n",
    "\n",
    "[3] Mikovol et al, ‚ÄúEfficient estimation of word representations in vector space‚Äù ICLR Workshop 2013.\n",
    "\n",
    "[4] Bojanowski et al., ‚ÄúEnriching word vectors with subword information‚Äù TACL 2017.\n",
    "\n",
    "[5] Pennington et al., ‚ÄúGlove: global vectors for word representation‚Äù, ACL 2014.\n",
    "\n",
    "[6] https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
